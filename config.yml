##################
# ImageTransformer
##################
tag: Null
random_seed: 0

##############
# Dataloader #
##############
# mnist, fmnist, cifar10, imagewoof, shakespeare
dataloader:
  dataset: "shakespeare"
  num_workers: 2

########
# Data #
########
data:
  n_classes: Null
  input_shape: Null

#########
# Model #
#########
transformer:
  n_blocks: 4
  max_sequence_length: 150
  image_to_sequence:
    patch_size: 1
    # sequence_length: 64  # TODO: Move sequence_length here for image transformer.
  token_embedding:
    is_trainable: true
    # Available encoding schemes: random_normal, sinusoidal
    encoding: "random_normal" 
  position_embedding:
    is_activated: true
    is_trainable: true
    # Available encoding schemes: ones, zeros, random_normal, sinusoidal
    encoding: "random_normal" 
  transformer_block:
    hidden_expansion: 2
    dropout_prob: 0
  self_attention:
    n_heads: 4
    head_dim: 8  # embedding dimension is n_heads * head_dim
    dropout_prob: 0
    use_bias: False
  mask:
    is_activated: true
    is_trainable: true
    # Available masks: causal, trainable_additive, trainable_multiplicative 
    type: "causal" 
  classifier:
    param1: None

###########
# Trainer #
###########
trainer:
  device: "gpu"   # gpu, cpu
  n_epochs: 500
  batch_size: 2048
  weight_decay: 0
  learning_rate: 6.0e-5
  # learning_rate_step_every: 200
  # learning_rate_gamma: 0.5
  lr_step_size: 200
  lr_gamma: 0.5
  grad_norm_clip: 1.0  # TODO: Use version below.
  gradient_clipping:
    is_activated: true
    max_norm: 1.0

###########
# Summary #
###########
summary:
  add_graph: false
  add_sample_batch: false
  add_hparams: false
  add_patch_embeddings:
    every_n_epochs: 10
  add_position_embeddings:
    every_n_epochs: 10
  add_token_embeddings:
    every_n_epochs: 10
  add_mask_weights:
    every_n_epochs: 10
  add_params_hist:
    every_n_epochs: -1
  save_train_stats:
    every_n_epochs: 1
  save_test_stats:
    every_n_epochs: -1
  save_model:
    every_n_epochs: 1

checkpoints:
  load_model: 0
  model_path: 0

###############
# Directories #
###############
dirs:  # TODO: dirs -> dir
  data: "data"
  runs: "runs"
  weights: "weights"
